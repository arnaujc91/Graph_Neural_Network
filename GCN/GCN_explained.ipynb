{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Based on https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
    "\n",
    "- useful:\n",
    "1. https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780\n",
    "2. https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
    "3. https://arxiv.org/pdf/1609.02907.pdf\n",
    "'''\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 1, 1, 1, 2, 2, 2, 2]),\n",
       " tensor([ 633, 1862, 2582,    2,  652,  654,    1,  332, 1454, 1666]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.edge_index[0][:10], dataset.data.edge_index[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Understand the structure of the dataset; it is a graph.\n",
    "# TODO : Understand GCNConv layer from PyTorch. -> https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html#the-messagepassing-base-class\n",
    "# https://tkipf.github.io/graph-convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding GCN Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add self loops one adds the identity matrix to the *adjacency matrix* **A**:\n",
    "\n",
    "\n",
    "$\n",
    "A \\to \\tilde{A} = A + I\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A major limitation is that **A** is typically not normalized and therefore the multiplication with **A** will completely change the scale of the feature vectors.\n",
    "\n",
    "Normalizing **A** such that all rows sum to one, i.e. $D^{‚àí1}A$, where **D** is the diagonal node degree matrix, gets rid of this problem. Multiplying with $D^{‚àí1}A$ now corresponds to taking the average of neighboring node features. In practice, dynamics get more interesting when we use a symmetric normalization, i.e. $D^{‚àí1/2}AD^{‚àí1/2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "D_{ij} =  \\delta_{ij}\\sum_{k}A_{kj} \\implies D^{-1/2}_{ij} = \\frac{1}{\\sqrt{ \\sum_{k}A_{kj}}}\\delta_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After including self-loops and normalization we are left with:\n",
    "$$\n",
    "H^{(i+1)} = \\sigma\\left( \\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}} H^{(i)}W^{(i)}\\right)\n",
    "$$\n",
    "where the weights $W$ are shared between all the nodes (similarly to a CNN in a grid) $\\implies$ two nodes that are far apart but have the similar neighboring features and structures should be classified similarly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PyTorch](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html) defines **message passing** through the following equation:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_i^{(k)} = \\gamma^{(k)} \\left( \\mathbf{x}_i^{(k-1)}, \\square_{j \\in \\mathcal{N}(i)} \\, \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{j,i}\\right) \\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with $\\mathbf{x}^{(k-1)}_i \\in \\mathbb{R}^F$, $\\mathbf{e}_{j,i} \\in \\mathbb{R}^D$ and:\n",
    "\n",
    "- $\\mathbf{x}^{(k-1)}_i \\rightarrow  $ features of node i in layer (k-1).\n",
    "- $\\mathbf{e}_{j,i} \\rightarrow $ edge features from node ùëó to node ùëñ.\n",
    "- $\\square \\rightarrow$  denotes a differentiable, permutation invariant function, e.g., sum, mean or max.\n",
    "- $\\phi \\rightarrow$ is a differentiable function such as MLPs (Multi Layer Perceptrons). In the [code implementation](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/gcn_conv.html#GCNConv) of the GCN Layer it corresponds to the function **message()**.\n",
    "- $\\gamma \\rightarrow$ is a differentiable function such as MLPs (Multi Layer Perceptrons). In the [code implementation](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/message_passing.html#MessagePassing) of the GCN Layer it corresponds to the function **update()**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more clarity we could represent the indices not shown in the PyTorch docu as *greek letters*.\n",
    "\n",
    "A simple example could be:\n",
    "$\n",
    "x^{(k)}_{i,\\alpha} = \\sigma\\left(A_{ij}x^{(k-1)}_{j,\\beta}W^{(k-1)}_{\\beta\\alpha}\\right)\n",
    "$\n",
    "\n",
    "Where $\\sigma$ is a non-linear activation function such as the ReLU function.\n",
    "\n",
    "$$\n",
    "x^{(k)}_{i,\\alpha}\n",
    "\\quad\n",
    "   \\begin{cases}\n",
    "      k & \\text{is the k'th layer}\\\\\n",
    "      i, & \\text{is the number of nodes}\\\\\n",
    "      \\alpha, & \\text{is the number of features}\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "$A$ is a square matrix, because we want the preserve the number of nodes. $W$ instead can be a non square matrix, such that we change the number of features of the node from layer $k$ to layer $k+1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\square \\rightarrow$  $Ax^{(k-1)}\\left(= A_{ij}x^{(k-1)}_{j,\\alpha}\\right)$\n",
    "- $\\phi \\rightarrow$ $\\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{j,i}\\right) \\equiv \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)}\\right) = \\sigma\\left(Ax^{(k-1)}W^{(k-1)}\\right)$\n",
    "- $\\gamma \\rightarrow$ is just the identity function, basically it does nothing.\n",
    "\n",
    "Where in the parenthesis I have included all the indices and used Einstein summation convention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets work it out in the particular example of the GCN Layer:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_i^{(k)} = \\sum_{j \\in \\mathcal{N}(i) \\cup \\{ i \\}} \\frac{1}{\\sqrt{\\deg(i)} \\cdot \\sqrt{\\deg(j)}} \\cdot \\left( \\mathbf{\\Theta} \\cdot \\mathbf{x}_j^{(k-1)} \\right)\\, ,\\quad \\left(=  \\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}} x^{(k-1)}\\mathbf{\\Theta}\\right)\n",
    "$$\n",
    "\n",
    "where $\\deg(i)$ is the degree of the node $\\rightarrow$ [Degree (graph theory)](https://en.wikipedia.org/wiki/Degree_(graph_theory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\square \\rightarrow$  $\\sum_{j \\in \\mathcal{N}(i) \\cup \\{ i \\}}$\n",
    "- $\\phi \\rightarrow$ $\\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{j,i}\\right) \\equiv \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)}\\right) =  \\frac{1}{\\sqrt{\\deg(i)} \\cdot \\sqrt{\\deg(j)}} \\cdot \\left( \\mathbf{\\Theta} \\cdot \\mathbf{x}_j^{(k-1)} \\right)$\n",
    "- $\\gamma \\rightarrow$ is just the identity function, basically it does nothing.\n",
    "\n",
    "I am actually not sure about what $\\phi$ does, because the normalization is done outside of *message* and the product with the weights $\\mathbf{\\Theta}$ as well (in the PyTorch code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{x}_i^{(k)} = \\square_{j \\in \\mathcal{N}(i)} \\, \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)}\\right) = \\sum_{j \\in \\mathcal{N}(i) \\cup \\{ i \\}} \\frac{1}{\\sqrt{\\deg(i)} \\cdot \\sqrt{\\deg(j)}} \\cdot \\left( \\mathbf{\\Theta} \\cdot \\mathbf{x}_j^{(k-1)} \\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   19],\n",
       "        [   0,   81],\n",
       "        [   0,  146],\n",
       "        ...,\n",
       "        [2707, 1328],\n",
       "        [2707, 1412],\n",
       "        [2707, 1414]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.x.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1.])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(dataset.data.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3831348.,   49216.])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.x.histc(bins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.x[2707, 1328]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data set structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Cora',\n",
       " 'root': '/tmp/Cora',\n",
       " 'transform': None,\n",
       " 'pre_transform': None,\n",
       " 'pre_filter': None,\n",
       " '__indices__': None,\n",
       " 'data': Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708]),\n",
       " 'slices': {'x': tensor([   0, 2708]),\n",
       "  'edge_index': tensor([    0, 10556]),\n",
       "  'y': tensor([   0, 2708]),\n",
       "  'train_mask': tensor([   0, 2708]),\n",
       "  'val_mask': tensor([   0, 2708]),\n",
       "  'test_mask': tensor([   0, 2708])},\n",
       " 'split': 'public'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'edge_index': tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "         [ 633, 1862, 2582,  ...,  598, 1473, 2706]]),\n",
       " 'edge_attr': None,\n",
       " 'y': tensor([3, 4, 4,  ..., 3, 3, 3]),\n",
       " 'pos': None,\n",
       " 'norm': None,\n",
       " 'face': None,\n",
       " 'train_mask': tensor([ True,  True,  True,  ..., False, False, False]),\n",
       " 'val_mask': tensor([False, False, False,  ..., False, False, False]),\n",
       " 'test_mask': tensor([False, False, False,  ...,  True,  True,  True])}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature matrix with shape [num_nodes, num_node_features]:  torch.Size([2708, 1433])\n",
      "\n",
      "Graph connectivity in COO format with shape [2, num_edges]:  torch.Size([2, 10556])\n",
      "\n",
      "Number of classes:  7\n"
     ]
    }
   ],
   "source": [
    "print('Node feature matrix with shape [num_nodes, num_node_features]: ', dataset.data.x.shape)\n",
    "print('\\nGraph connectivity in COO format with shape [2, num_edges]: ', dataset.data.edge_index.shape)\n",
    "print('\\nNumber of classes: ', dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2707), tensor(2707))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(dataset.data.edge_index[0]), max(dataset.data.edge_index[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. The model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCNConv??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_hidden=16, n_output=1):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, n_hidden)\n",
    "        self.conv2 = GCNConv(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, data):\n",
    "        ''' x (Tensor): Node feature matrix. Shape [num_nodes, num_node_features]'''\n",
    "        ''' edge_index (LongTensor): Graph connectivity in COO format. Shape [2, num_edges]'''\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(n_output=dataset.num_classes).to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0053, -0.0312,  0.0071, -0.0277,  0.0302, -0.0191,  0.0528,  0.0823,\n",
       "         -0.0631,  0.0729,  0.0596,  0.0298,  0.0294, -0.0091,  0.0151,  0.0407],\n",
       "        [-0.0509,  0.2361, -0.0555,  0.2472, -0.0025,  0.1550, -0.0704, -0.0828,\n",
       "         -0.0008,  0.0061, -0.0575, -0.0340,  0.0319, -0.0304,  0.1290, -0.1260],\n",
       "        [-0.0963,  0.0383, -0.0828, -0.0552,  0.0221,  0.0051,  0.0631,  0.1872,\n",
       "         -0.0259, -0.0057,  0.1380,  0.1858, -0.1658,  0.0753, -0.0261, -0.0763]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['conv1']._parameters['weight'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 7])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / int(data.test_mask.sum())\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
